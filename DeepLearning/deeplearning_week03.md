# 신경망
## 활성화 함수
### ReLU 함수
- 입력이 0을 넘으면 그 입력을 그대로 출력, 0이하면 0을 출력하는 함수
- h(x) = x > 0 ? x : 0

### 시그모이드 vs ReLU 차이
- 시그모이드
	- 0 < h(x) < 1
	- 거의 0에 가까워서 미분을 했을때 값이 제대로 나오지 않음
- ReLU 
	- 미분했을 때, 값이 커짐

### Linear( 선형 ) 함수 조건
1. f(x+y) = f(x) + f(y)
2. f(ax) = a + f(x) 
- 위 두개를 만족하면 선형 함수
- 위 두개 식 중에 하나만 만족하면 선형함수임

## 다차원 배열의 계산
- (행-row,렬-colum)

### 행렬 곱 ( 행렬의 내적 )
- (3, 2) * (2, 1) = (3,1)
	- 열1과 행1이 같아야 연산이 가능하다
	- 결과값을 축소시킬수 있어서 사용
- np.dot( list1, list2 )
	- np.dot( l1, l2 ) != np.dot( l2, l1 )
	- list1의 열 수와 list2의 행 수가 같아야함

### 신경망의 내적
```python
x = np.array( [1,2] )
w = np.array( [[1,3,5],[2,4,6]] )

x.shape
# (2,)
w.shape
# (2,3)

print( np.dot(x,w) )
# [5 11 17]
```

## 신경망 구현하기
- 입력으로 구하고싶은 출력의 갯수를 생각해서 설계하면 됨
	- 모든 층 n에서, n-1이 x=(1,2)이고 n층의 출력을 3개를 원한다면 W = (2,3) 을 한다면, (1,3)의 출력이 나온다
	- 나온 출력에 활성함수를 적용해 값을 구하고, 마지막 출력층에선 항등함수를 사용한다

## 츨력층 설계하기
- 신경망은 분류와 회귀 모두에 이용할 수 있음
	- 회귀에는 항등함수, 분류는 소프트맥스 함수를 사용함
		- 분류 : 데이터가 어떤 분류에 속하는가?
		- 회귀 : 입력 데이터에서 수치를 예측
			- 사진속 물건의 무게를 예측 => 회귀

### 항등 함수 ( Identify function )
- 입력을 그대로 출력함
	- 입력과 출력이 항상 같음

### 소프트맥스 함수 ( Softmax function )
- 출력층은 모든 입력 신호로 부터 화살표를 받음
	- 출력층의 각 뉴런이 모든 입력신호에서 영향을 받기 때문
- 지수함수를 이용하는 이유
	- 
```python
def softmax(a):
	exp_a = np.exp(a)
	sum_exp_a = np.sum(exp_a)
	y = exp_a / sum_exp_a

	return y
```

#### 구현시 주의점
- 지수를 이용하므로 오버플로를 유의해야함
	- e^1000은 무한대 inf가 되어 돌아옴
	- 지수함수 계산을 할 때, exp( a + C' )
		- C라는 숫자를 곱해 지수함수로 옮기면 logC가 됨
		- 결국 logC는 임의의 숫자 C'가 됨
```python
def softmax(a):
	c = np.max(a)
	exp_a = np.exp(a - c)
	sum_exp_a = np.sum(exp_a)
	y = exp_a / sum_exp_a

	return y
```

#### 소프트맥스 함수의 특징
- 출력이 0과 1.0 사이
- 함수 출력의 총합은 1 **
	- 이 성질 덕분에 소프트맥스 함수의 출력을 '확률'로 해석 가능함
- 수치값의 극명한 차이와 비슷한 차이를 디테일 하게 보여줌
	- 학습을 할 때 유용함, 정답과의 차이를 봤을때 차이를 극명하게 보여주면 다름이 확연히 들어나므로
		- 강아지1와 강아지2
	- 추론을 할 때는 빼도됨
```python
softmax( np.array([2.7, 2.8, 2.9]) )
# [ 0.30060961  0.33222499  0.3671654 ]

softmax( np.array([2, 3, 10]) )
#[  3.35044712e-04   9.10745952e-04   9.98754209e-01]
```

#### 출력층의 뉴런수
- 풀려는 문제에 맞게 정해야함
	- 분류에서는 분류하고 싶은 클래스의 수로 설정하는 것이 일반적임
		- 클래스 : 분류되는 경우
		- 책 예제의 경우 0-9까지의 10가지 숫자로 분류 될 수 있으므로 

## Random variable
: 확률변수
- 식이 scalar(값), vector(가중치), matrix(입력값) 이 세개로 구성되있음 

---
## 참고링크
* [블로그 - 01.활성함수(activation function) - Sigmoid, ReLU](http://astralworld58.tistory.com/62
* [블로그 - 해커에게 전해들은 머신러닝 #3](https://tensorflow.blog/해커에게-전해들은-머신러닝-3/)